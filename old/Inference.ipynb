{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image\n",
    "from FCN8 import FCN8s\n",
    "from segnet import segnet\n",
    "from createDataset import MyDataset\n",
    "from utils import *\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "# from tensorboardX import SummaryWriter\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "print(device)\n",
    "dataroot = 'data/'\n",
    "batch = 16\n",
    "num_classes=39\n",
    "img_size = (128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### Transforms ###########\n",
    "mean_std = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "input_transforms = transforms.Compose([\n",
    "        transforms.Resize(img_size, interpolation = 1),\n",
    "        transforms.ToTensor(),\n",
    "])\n",
    "to_tensor =  transforms.Compose([transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########### Dataloader ###########\n",
    "seg_path = 'gt_labels/'\n",
    "img_path = 'leftImg8bit_orig/'\n",
    "\n",
    "colpath = os.path.join(dataroot, img_path)\n",
    "segpath = os.path.join(dataroot, seg_path)\n",
    "\n",
    "# colimg = os.listdir(colpath)\n",
    "# segimg = os.listdir(segpath)\n",
    "\n",
    "X_train = os.listdir(os.path.join(colpath,'train'))\n",
    "Y_train = os.listdir(os.path.join(segpath,'train'))\n",
    "X_val = os.listdir(os.path.join(colpath,'val'))\n",
    "Y_val = os.listdir(os.path.join(segpath,'val'))\n",
    "X_test = os.listdir(os.path.join(colpath,'test'))\n",
    "Y_test = os.listdir(os.path.join(segpath,'test'))\n",
    "\n",
    "\n",
    "                \n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(colimg, segimg, random_state=123)\n",
    "\n",
    "train_dataset = MyDataset(X_train, Y_train, dataroot, in_transforms = input_transforms, size = img_size,\n",
    "\tphase = 'train')\n",
    "test_dataset = MyDataset(X_test, Y_test, dataroot, in_transforms = input_transforms, size = img_size,\n",
    "\tphase = 'test')\n",
    "val_dataset = MyDataset(X_val, Y_val, dataroot, in_transforms = input_transforms, size = img_size,\n",
    "\tphase = 'val')\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch, shuffle = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch, shuffle=False)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset,batch_size=batch,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('id_to_color.txt', 'r') as f:\n",
    "    id_to_color_map = json.load(f)\n",
    "\n",
    "id_to_color_map = {int(key): value for key, value in id_to_color_map.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertImgToSegColMap(img):\n",
    "    new_img = np.zeros((img.shape[0],img.shape[1],3))\n",
    "#     print(new_img.shape,img.shape)\n",
    "    valid_keys = np.unique(img)\n",
    "    \n",
    "#     new_img[:,:,0],new_img[:,:,1],new_img[:,:,2] = img[:,:,0],img[:,:,0],img[:,:,0]\n",
    "    for key in valid_keys:\n",
    "#         print(key)\n",
    "        x,y = np.where(img==key)\n",
    "#         print(len(x),len(y))\n",
    "        \n",
    "        coords = [list(coord) for coord in zip(x,y)]\n",
    "#         print(len(coords))\n",
    "#         print(max(x),max(y))\n",
    "#         print(id_to_color_map[key])\n",
    "        for coord in coords:\n",
    "\n",
    "#             print(coord)\n",
    "            \n",
    "            new_img[coord[0],coord[1]] = id_to_color_map[key]\n",
    "    return new_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculatePixelAcc(predictedImg,gt_img):\n",
    "    pred_arr = predictedImg.reshape(-1)\n",
    "    gt_img = gt_img.reshape(-1)\n",
    "    corr_arr = np.zeros_like(pred_arr)\n",
    "    corr_arr[pred_arr==gt_img] = 1\n",
    "    return sum(corr_arr)/pred_arr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDataImbalance(root,img_dir):\n",
    "    dataPath = os.path.join(root,img_dir)\n",
    "    count_labels = np.zeros((num_classes))\n",
    "    all_labels = os.listdir(dataPath)\n",
    "    for idx,label in enumerate(all_labels):\n",
    "        \n",
    "        gt_lab = cv2.imread(os.path.join(root,img_dir,label),0)\n",
    "        un_labs = np.unique(gt_lab)\n",
    "        count_labels[un_labs]+=1\n",
    "\n",
    "#     print(un_labs)\n",
    "    return count_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tic():\n",
    "    # Homemade version of matlab tic and toc functions\n",
    "    import time\n",
    "    global startTime_for_tictoc\n",
    "    startTime_for_tictoc = time.time()\n",
    "\n",
    "def toc():\n",
    "    import time\n",
    "    if 'startTime_for_tictoc' in globals():\n",
    "        print (\"Elapsed time is \" + str(time.time() - startTime_for_tictoc) + \" seconds.\")\n",
    "    else:\n",
    "        print (\"Toc: start time not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d5f8747ef6aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcount_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckDataImbalance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-e0b3a0501cf3>\u001b[0m in \u001b[0;36mcheckDataImbalance\u001b[0;34m(root, img_dir)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mgt_lab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mun_labs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_lab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcount_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mun_labs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count_labels = checkDataImbalance(segpath,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_labels.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iou 0.587794752468\n",
      "Elapsed time is 4.31827092171 seconds.\n",
      "Mean IOU =  0.00037014782901\n",
      "Total Pix Acc =  0.000279317920428\n"
     ]
    }
   ],
   "source": [
    "saved_models =['weighted_fcn.pth']\n",
    "root = 'demoSet'\n",
    "gtDir = 'gt_labels'\n",
    "col_Dir = 'gt_labels_colored'\n",
    "orig_Dir = 'leftImg8bit_orig'\n",
    "\n",
    "saved_output_dir = 'saved_outputs'\n",
    "all_imgs = os.listdir(os.path.join(root,orig_Dir))\n",
    "all_test_imgs = os.listdir(os.path.join(colpath,'test'))\n",
    "\n",
    "total_images = len(all_test_imgs)\n",
    "total_iou = 0\n",
    "total_pix_acc = 0\n",
    "# print(id_to_color_map)\n",
    "#### test model accuracy #######\n",
    "for saved_model in saved_models:\n",
    "   \n",
    "    model = FCN8s(num_classes)\n",
    "#     model = segnet(num_classes)\n",
    "    model.load_state_dict(torch.load(saved_model))\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tic()\n",
    "    for idx,img_ in enumerate(all_test_imgs):\n",
    "         if idx==4:\n",
    "            img1 = Image.open(os.path.join(colpath, 'test' ,img_))\n",
    "            img = input_transforms(img1)\n",
    "            img.unsqueeze_(0)\n",
    "            img = img.to(device)\n",
    "    #         print(img.size())\n",
    "\n",
    "    #             optimizer.zero_grad()\n",
    "            output = model(img)\n",
    "\n",
    "    #             print(output.size())\n",
    "            output.squeeze_(0)\n",
    "            output_labels = torch.argmax(output,dim=0)\n",
    "    #             print(output_labels.size())\n",
    "    #             print(output_labels)\n",
    "\n",
    "            np_img = output_labels.detach().cpu().numpy()\n",
    "            np_img = np_img.reshape(np_img.shape[0],np_img.shape[1],1)\n",
    "    #             print(np_img.shape)\n",
    "\n",
    "    #             np.save('ac.npy',np_img)\n",
    "            img1.save('orig.png')\n",
    "            img_col = Image.open(os.path.join(dataroot,col_Dir,'test',img_))\n",
    "            img_col.save('col.png')\n",
    "            np_img_res = cv2.resize(np_img,img1.size,interpolation = cv2.INTER_NEAREST)\n",
    "            cv2.imwrite('out.png',np_img_res)\n",
    "\n",
    "            gt_img_name = img_[:img_.find('_')]+str('_id_gt.png')\n",
    "\n",
    "            gt_img = cv2.imread(os.path.join(segpath,'test',gt_img_name),0)\n",
    "\n",
    "            gt_tsor_img = Image.open(os.path.join(segpath,'test',gt_img_name))\n",
    "    #             print(gt_tsor_img.size)\n",
    "    #             gt_tsor_img = gt_tsor_img[:,:,0]\n",
    "    #             gt_tsor_img = Image.fromarray(gt_img)\n",
    "\n",
    "    #             cv2.imwrite('testing.png',gt_img)\n",
    "\n",
    "    #             gt_tsor = input_transforms(gt_tsor_img)\n",
    "    #             gt_tsor = gt_tsor[0,:,:]\n",
    "    #             print('Tsor',gt_tsor.shape)\n",
    "    #             gt_tsor = gt_tsor.long()\n",
    "    #             gt_tsor.unsqueeze_(0)\n",
    "    #             gt_tsor.unsqueeze_(0)\n",
    "    #             gt_tsor = gt_tsor.to(device)\n",
    "    #             print('this',gt_img.shape)\n",
    "    #             print(gt_img[:,:,0]-gt_img[:,:,1])\n",
    "\n",
    "\n",
    "            col_gt_img = convertImgToSegColMap(gt_img)\n",
    "\n",
    "\n",
    "            cv2.imwrite('col_gt.png',col_gt_img)\n",
    "\n",
    "            col_seg_img = convertImgToSegColMap(np_img_res)\n",
    "\n",
    "            cv2.imwrite('col_seg.png',col_seg_img)\n",
    "\n",
    "\n",
    "    #             print(np_img_res.shape)\n",
    "    #             print(np.array(gt_img).shape)\n",
    "    #             gt_img = np.array(gt_img)[:,:,0]\n",
    "    #             print(gt_img)\n",
    "    #             print(gt_img.shape)\n",
    "    #             print(gt_img.reshape(-1).shape)\n",
    "            pix_acc = calculatePixelAcc(np_img_res,gt_img)\n",
    "            output = output.unsqueeze_(0)\n",
    "    #         print(output.size())\n",
    "    #             test = torch.max(output.data, 1)[1]\n",
    "    #             test = test.long()\n",
    "    #             test = test.to(device)\n",
    "\n",
    "            out_labels = torch.max(output.data, 1)[1]\n",
    "    #             out_labels.unsqueeze_(0)\n",
    "            out_labels_np = out_labels.cpu().numpy().transpose((1,2,0))\n",
    "\n",
    "    #             print('outlabels',out_labels_np.shape)\n",
    "    #             print('gt_tsor',gt_tsor.size())\n",
    "    #             print(gt_tsor)\n",
    "\n",
    "            gt_res_img = cv2.resize(gt_img,(128,128),interpolation = cv2.INTER_NEAREST)\n",
    "            gt_res_img = gt_res_img.reshape(gt_res_img.shape[0],gt_res_img.shape[1],1)\n",
    "    #             print('gt_img_res',gt_res_img.shape)\n",
    "            intersection = np.bitwise_and(out_labels_np,gt_res_img)\n",
    "            union = np.bitwise_or(out_labels_np,gt_res_img)\n",
    "    #             print(intersection,union)\n",
    "            iou = np.mean(np.sum(intersection)/np.sum(union))\n",
    "            print('iou',iou)\n",
    "    #             iou = torch.mean((torch.sum(intersection).float()/torch.sum(union).float()).float())\n",
    "    #             print('iou = ',checkiou(out_labels,gt_tsor,1).item())\n",
    "            total_iou+=iou\n",
    "            total_pix_acc+=pix_acc\n",
    "    toc()\n",
    "    print(\"Mean IOU = \",total_iou/total_images)\n",
    "    print(\"Total Pix Acc = \",total_pix_acc/total_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2380352644836272"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "378/total_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
